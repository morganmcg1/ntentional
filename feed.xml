<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://www.ntentional.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.ntentional.com/" rel="alternate" type="text/html" /><updated>2020-05-05T12:16:45-05:00</updated><id>https://www.ntentional.com/feed.xml</id><title type="html">ntentional</title><subtitle>Morgan McGuire's machine learning journey through blogs and code</subtitle><entry><title type="html">ICLR 2020: Efficient NLP - Transformers</title><link href="https://www.ntentional.com/nlp/efficient-nlp/transformers/2020/05/05/iclr-hghlights.html" rel="alternate" type="text/html" title="ICLR 2020: Efficient NLP - Transformers" /><published>2020-05-05T00:00:00-05:00</published><updated>2020-05-05T00:00:00-05:00</updated><id>https://www.ntentional.com/nlp/efficient-nlp/transformers/2020/05/05/iclr-hghlights</id><content type="html" xml:base="https://www.ntentional.com/nlp/efficient-nlp/transformers/2020/05/05/iclr-hghlights.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-05-05-iclr-hghlights.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;I was lucky enough to volunteer and attend (virtual) ICLR 2020. It delivered a huge amount of learning for me and I was fortunate to join some really great discussions.&lt;/p&gt;
&lt;p&gt;Efficient NLP was big focus of many of the papers and here I will focus on a few of the more well known transformer architectures proposed over the past year or so; Reformer, ELECTRA, Lite Transformer and ALBERT. Towards the end of this article I also mention additional ICLR summaries that are worth reading ðŸ™‚&lt;/p&gt;
&lt;h3 id=&quot;Note:-ICLR-Videos-Now-Online!&quot;&gt;Note: ICLR Videos Now &lt;a href=&quot;http://iclr.cc/virtual_2020/&quot;&gt;Online&lt;/a&gt;!&lt;a class=&quot;anchor-link&quot; href=&quot;#Note:-ICLR-Videos-Now-Online!&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;All of the ICLR paper talks and slides are now online, I &lt;strong&gt;highly recommend&lt;/strong&gt; watching the 5 to 15minutes videos accompanying each of the papers below for some excellent summaries and additional understanding

&lt;center&gt;
    &lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;&lt;a href=&quot;https://twitter.com/hashtag/ICLR2020?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#ICLR2020&lt;/a&gt; Public Archive - &lt;a href=&quot;https://t.co/EpXWIK0ujS&quot;&gt;https://t.co/EpXWIK0ujS&lt;/a&gt; &lt;br /&gt;* ~700 short talks with synced slides, papers, and code&lt;br /&gt;* 8 keynotes with moderated QA &lt;br /&gt;* 15 workshops on topics ranging from climate change to AfricaNLP. &lt;a href=&quot;https://t.co/FVX2JJUYVZ&quot;&gt;pic.twitter.com/FVX2JJUYVZ&lt;/a&gt;&lt;/p&gt;&amp;mdash; Sasha Rush (@srush_nlp) &lt;a href=&quot;https://twitter.com/srush_nlp/status/1257287875323969537?ref_src=twsrc%5Etfw&quot;&gt;May 4, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Efficient-NLP---Transformers&quot;&gt;Efficient NLP - Transformers&lt;a class=&quot;anchor-link&quot; href=&quot;#Efficient-NLP---Transformers&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;New transformer architectures that promise less compute-intense NLP training, in order of my excitement to use them:&lt;/p&gt;
&lt;h3 id=&quot;&amp;#9889;-Reformer:-The-Efficient-Transformer-&amp;#9889;&quot;&gt;&amp;#9889; &lt;a href=&quot;https://iclr.cc/virtual/poster_rkgNKkHtvB.html&quot;&gt;Reformer: The Efficient Transformer&lt;/a&gt; &amp;#9889;&lt;a class=&quot;anchor-link&quot; href=&quot;#&amp;#9889;-Reformer:-The-Efficient-Transformer-&amp;#9889;&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Reformer enables training on &lt;strong&gt;much longer&lt;/strong&gt; sequences than BERT-like models (e.g. document-length sequences instead of 512 token length sequences) much more efficiently&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Reformer introduces a couple of techniques that improve both time and memory efficiency:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Technique 1: Reversible residual connection layers&lt;/strong&gt; (originally used in computer vision in &lt;a href=&quot;https://ameroyer.github.io/reading-notes/architectures/2019/05/07/the_reversible_residual_network.html&quot;&gt;RevNets&lt;/a&gt;) instead of the standard residual layers improves &lt;strong&gt;memory efficiency:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/reformer_rev.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Technique 2: Locality-Sensitive Hashing (LSH)&lt;/strong&gt; based attention replaces dot-product attention (and is much faster) which reduces the &lt;strong&gt;time complexity:&lt;/strong&gt; 
&lt;img src=&quot;/images/copied_from_nb/my_icons/reformer_lsh.png&quot; alt=&quot;&quot; /&gt; &lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;The 15 minute ICLR paper presentation video linked above really helps better understand these concepts&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/lucidrains/reformer-pytorch&quot;&gt;&lt;strong&gt;A PyTorch Reformer implementation can be found here&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;&amp;#9889;-ELECTRA:-Pre-training-Text-Encoders-as-Discriminators-Rather-Than-Generators-&amp;#9889;&quot;&gt;&amp;#9889; &lt;a href=&quot;https://iclr.cc/virtual/poster_r1xMH1BtvB.html&quot;&gt;ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators&lt;/a&gt; &amp;#9889;&lt;a class=&quot;anchor-link&quot; href=&quot;#&amp;#9889;-ELECTRA:-Pre-training-Text-Encoders-as-Discriminators-Rather-Than-Generators-&amp;#9889;&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;ELECTRA brings a couple of novelties, resulting in a much more computationally efficient transformer to train. It is trained with:&lt;ul&gt;
&lt;li&gt;a Generator-Discriminator setup and &lt;/li&gt;
&lt;li&gt;a new pre-training task called Replaced Token Detection&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The Generator is trained to replace masked tokens (as per the standard MLM task), the Discriminator then tries to identify the token that has been replaced&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/electra.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One subtle thing to note is that if the generator happens to generate the correct token then that token is considered &quot;real&quot; instead of &quot;fake&quot; &lt;/li&gt;
&lt;li&gt;ELECTRA-small can be trained on a single V100 GPU (4 days) &lt;/li&gt;
&lt;li&gt;It is slower per epoch than other transformers, but it converges faster resulting in an overall faster training:&lt;blockquote&gt;&lt;p&gt;the model learns from all input tokens instead of just the small masked-out subset, making it more computationally efficient&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Very strong results and it's performance scales up as the architecture is made larger&lt;/li&gt;
&lt;li&gt;Lots more interesting results and experiment discussion can be found in the paper&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://huggingface.co/transformers/model_doc/electra.html?highlight=electra&quot;&gt;&lt;strong&gt;A HuggingFace ELECTRA Implementation is here&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;&amp;#9889;-Lite-Transformer-with-Long-Short-Range-Attention-&amp;#9889;&quot;&gt;&amp;#9889; &lt;a href=&quot;https://iclr.cc/virtual/poster_ByeMPlHKPH.html&quot;&gt;Lite Transformer with Long-Short Range Attention&lt;/a&gt; &amp;#9889;&lt;a class=&quot;anchor-link&quot; href=&quot;#&amp;#9889;-Lite-Transformer-with-Long-Short-Range-Attention-&amp;#9889;&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Introduces Long-Short Range Attention (LRSA) which results in a reduction in model computation between 2.5x and 3x compared to original Transformer.
&lt;img src=&quot;/images/copied_from_nb/my_icons/lite_summary.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The new architecture enables 2 different perspectives on the input sequence:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;...one group of heads specializes in the local context modeling (by convolution) while another group specializes in the long-distance relationship modeling (by attention)...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The LSRA architecture and where the attention is focussed can be seen here:&lt;img src=&quot;/images/copied_from_nb/my_icons/lite_2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Lite Transformer performs well against the original Transformer for translation, summarisation and language modelling&lt;/li&gt;
&lt;li&gt;One thing I liked is that Lite Transformer looks at performance under mobile-like constraints, defined by the authros as 10M parameters and 1G FLOPs &lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/mit-han-lab/lite-transformer&quot;&gt;&lt;strong&gt;Lite Transformer code (PyTorch) is available from the authors here&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;&amp;#9889;-ALBERT:-A-Lite-BERT-for-Self-supervised-Learning-of-Language-Representations-&amp;#9889;&quot;&gt;&amp;#9889; &lt;a href=&quot;https://iclr.cc/virtual/poster_H1eA7AEtvS.html&quot;&gt;ALBERT: A Lite BERT for Self-supervised Learning of Language Representations&lt;/a&gt; &amp;#9889;&lt;a class=&quot;anchor-link&quot; href=&quot;#&amp;#9889;-ALBERT:-A-Lite-BERT-for-Self-supervised-Learning-of-Language-Representations-&amp;#9889;&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;ALBERT is 18x smaller model than BERT-large and can be trained 1.7x faster while still outperforming it&lt;/li&gt;
&lt;li&gt;The two techniques used to reduce its size are:&lt;ul&gt;
&lt;li&gt;Reduce the vocabulary embedding size; they reduce the matrix size by projecting it to a lower dimension. e.g. an input one-hot encoded matrix of size 30,000 is reduced to a much smaller sized matix which is then used&lt;/li&gt;
&lt;li&gt;Cross-layer parameter sharing; they use the same operations and repeat them multiple times. This helps the parameter size of the network growing as layers as added &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ALBERT uses 3 training tricks to further improve its performance:&lt;ol&gt;
&lt;li&gt;Uses MLM and Sentence Order Prediction (SOP), a self-supervised loss that focuses on modeling inter-sentence coherence&lt;/li&gt;
&lt;li&gt;Does not use dropout (due to the huge amount of data available)&lt;/li&gt;
&lt;li&gt;Uses 10x more data than BERT-Base&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://huggingface.co/transformers/model_doc/albert.html&quot;&gt;&lt;strong&gt;HuggingFace PyTorch ALBERT code can be found here&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/albert.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;Other-Great-Summaries-to-Read&quot;&gt;Other Great Summaries to Read&lt;a class=&quot;anchor-link&quot; href=&quot;#Other-Great-Summaries-to-Read&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Other great summaries from ICLR attendees are below, the Google Doc in Yacine's tweet below gives brief summaries to even more papers that I haven't covered here&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://twitter.com/mstanojevic118/status/1255987903408287745&quot;&gt;Marija Stanojevic on mentorship tips for aspiring ML Researchers&lt;/a&gt;&lt;/strong&gt;, &lt;a href=&quot;https://twitter.com/mstanojevic118&quot;&gt;@mstanojevic118&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://twitter.com/YJernite/status/1256284687242330112&quot;&gt;Yacine Jernite with additional paper summaries&lt;/a&gt;&lt;/strong&gt;, &lt;a href=&quot;https://twitter.com/YJernite&quot;&gt;@YRnite&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.analyticsvidhya.com/blog/2020/05/key-takeaways-iclr-2020/&quot;&gt;Analytics Vidhya with a summary of the event and what the most used opensource tools were&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;To-Close&quot;&gt;To Close&lt;a class=&quot;anchor-link&quot; href=&quot;#To-Close&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Research work on efficient NLP is moving rapidly and it was fascinating to see so many different approaches on display at ICLR this year, myself and my single GPU are super excited to see how fast things will develop this year ðŸ˜†&lt;/p&gt;
&lt;p&gt;This was also the first ML conference I attended and found the (covid-caused) virtual format to work exceptionally well, my huge congrates to all of the organisers involved in pulling off a massive amount of work in such a short amount of time!&lt;/p&gt;
&lt;p&gt;As always, I would love to hear if you have any comments, thoughts or criticisms at &lt;strong&gt;&lt;a href=&quot;www.twitter.com/mcgenergy&quot;&gt;@mcgenergy&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Morgan McGuire</name></author><summary type="html"></summary></entry><entry><title type="html">FastHugs: Language Modelling with Tranformers and Fastai</title><link href="https://www.ntentional.com/nlp/transformers/training%20technique/classification/2020/04/24/fasthugs_language_model.html" rel="alternate" type="text/html" title="FastHugs: Language Modelling with Tranformers and Fastai" /><published>2020-04-24T00:00:00-05:00</published><updated>2020-04-24T00:00:00-05:00</updated><id>https://www.ntentional.com/nlp/transformers/training%20technique/classification/2020/04/24/fasthugs_language_model</id><content type="html" xml:base="https://www.ntentional.com/nlp/transformers/training%20technique/classification/2020/04/24/fasthugs_language_model.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-24-fasthugs_language_model.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;This aims to be an end-to-end description with code of how to train a transformer language model using fastai (v2) and HuggingFace, enjoy!&lt;/p&gt;
&lt;h2 id=&quot;TL;DR&quot;&gt;TL;DR&lt;a class=&quot;anchor-link&quot; href=&quot;#TL;DR&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Main interesting bits in this notebook:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Provides full code to train a transformer (RoBERTa) using a Masked Language Model task&lt;/li&gt;
&lt;li&gt;Utilise's many of HuggingFace's tokenizer features within fastai&lt;/li&gt;
&lt;li&gt;Make predictions of masked tokens like this:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/fastai_logo.png&quot; alt=&quot;image&quot; title=&quot;RoBERTa&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;Before-we-get-started&quot;&gt;Before we get started&lt;a class=&quot;anchor-link&quot; href=&quot;#Before-we-get-started&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;First off, huge thanks as always to both the Fastai and HuggingFace teams for giving so much back to the community by open-sourcing so much&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For an example of &lt;strong&gt;text sequence classification&lt;/strong&gt; using HuggingFace and fastai, have a look at my previous notebook &lt;a href=&quot;https://github.com/morganmcg1/fasthugs/blob/master/fasthugs_seq_classification.ipynb&quot;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;This tutorial is heavily based on HuggingFace's &lt;a href=&quot;https://huggingface.co/blog/how-to-train&quot;&gt;&quot;How to train a new language model from scratch using Transformers and Tokenizers&quot;&lt;/a&gt;  tutorial, I highly recommend checking that out too. I try and highlight throughout where code has been used, borrowed or inspired by HuggingFace's code.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;MLM-Tranform&quot;&gt;MLM Tranform&lt;a class=&quot;anchor-link&quot; href=&quot;#MLM-Tranform&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;I feel the most useful thing in this notebook is the &lt;code&gt;MLMTokensLabels&lt;/code&gt; transform*. This carries out the Masked Language Model task that RoBERTa was originally trained on.&lt;/p&gt;
&lt;p&gt;This will take tokens ids (tokens after the have been numericalized), select a subset and either mask a certain amount of them (for prediction) or replace them with other random token ids (for regularisation). This transform also creates our labels by copying the input token ids and masking the tokens that do &lt;strong&gt;not&lt;/strong&gt; need to be predicted, so that no loss is calculated on them.&lt;/p&gt;
&lt;p&gt;Note the if you wish to train BERT or other transformer language models you will probably need to use a different task, e.g. BERT was trained on 2 tasks simultaneously, MLM and Next Sentence Prediction (NSP). Have a look at any blog posts or arxiv paper of the transformer of interest to find which task was used to pretrain it.&lt;/p&gt;
&lt;p&gt;*This transform code is a re-write of the &lt;code&gt;mask_tokens&lt;/code&gt; function used in HugginFace's tutorial, &lt;a href=&quot;https://github.com/huggingface/transformers/blob/a21d4fa410dc3b4c62f93aa0e6bbe4b75a101ee9/examples/run_language_modeling.py#L66&quot;&gt;code here&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Pretraining-+-Fine-Tuning:&quot;&gt;Pretraining + Fine-Tuning:&lt;a class=&quot;anchor-link&quot; href=&quot;#Pretraining-+-Fine-Tuning:&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;As shown in ULMFit, MultiFiT, and elsewhere, you will get better results on your downstream task if you first fine-tune your pretrained model with the text of the same domain as your pretrained task. e.g. training an IMDB movie review classifier who's language model was trained on wikipedia text.

&lt;center&gt;
    &lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;1/ Really excited about this one! &amp;quot;Don&amp;#39;t Stop Pretraining: Adapt Language Models to Domains and Tasks&amp;quot; is live! With &lt;a href=&quot;https://twitter.com/anmarasovic?ref_src=twsrc%5Etfw&quot;&gt;@anmarasovic&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/swabhz?ref_src=twsrc%5Etfw&quot;&gt;@swabhz&lt;/a&gt; , &lt;a href=&quot;https://twitter.com/kylelostat?ref_src=twsrc%5Etfw&quot;&gt;@kylelostat&lt;/a&gt; , &lt;a href=&quot;https://twitter.com/i_beltagy?ref_src=twsrc%5Etfw&quot;&gt;@i_beltagy&lt;/a&gt; , Doug Downey, and &lt;a href=&quot;https://twitter.com/nlpnoah?ref_src=twsrc%5Etfw&quot;&gt;@nlpnoah&lt;/a&gt;, to appear at ACL2020. &lt;br /&gt;Paper: &lt;a href=&quot;https://t.co/hVbSQYnclk&quot;&gt;https://t.co/hVbSQYnclk&lt;/a&gt; &lt;br /&gt;Code: &lt;a href=&quot;https://t.co/7wKgE1mUme&quot;&gt;https://t.co/7wKgE1mUme&lt;/a&gt;&lt;/p&gt;&amp;mdash; Suchin Gururangan (@ssgrn) &lt;a href=&quot;https://twitter.com/ssgrn/status/1253498613558243328?ref_src=twsrc%5Etfw&quot;&gt;April 24, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;/p&gt;
&lt;h2 id=&quot;Using-a-Custom-Tokenizer?&quot;&gt;Using a Custom Tokenizer?&lt;a class=&quot;anchor-link&quot; href=&quot;#Using-a-Custom-Tokenizer?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;This code has not been tested using a custom tokenizer. You may want to do so if your text is very specific to a certain domain. If so then you'll have to add a number of attributes to your tokenzier to be able to use the code here. I really recommend the &lt;a href=&quot;https://huggingface.co/blog/how-to-train&quot;&gt;HuggingFace language model tutorial linked above&lt;/a&gt; for an example of training your own tokenizer with your own dataset&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Data&quot;&gt;Data&lt;a class=&quot;anchor-link&quot; href=&quot;#Data&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;We'll use the &lt;code&gt;IMDB_SAMPLE&lt;/code&gt; here, pretending we are fine-tuning our transformer model before doing sentiment classification on IMDB. If you are pretraining a language model from scratch you'd aim to use a larger, more generic source like a wikipedia dataset. fastai have the full &lt;code&gt;WikiText103&lt;/code&gt; (100 million tokens) dataset available for easy download here if you'd like to train an enligh language model from scratch:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;path = untar_data(URLs.WIKITEXT)&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;HuggingFace-Auto-Classes&quot;&gt;HuggingFace Auto Classes&lt;a class=&quot;anchor-link&quot; href=&quot;#HuggingFace-Auto-Classes&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;HuggingFace have a numer of useful &lt;a href=&quot;https://huggingface.co/transformers/model_doc/auto.html&quot;&gt;&quot;Auto&quot; classes&lt;/a&gt; that enable you to create different models and tokenizers by changing just the model name.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;AutoModelWithLMHead&lt;/code&gt; will define our Language model for us. This can either be a pretrained model or a randomly initialised model&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AutoTokenizer&lt;/code&gt; will load our tokenizer and enable us grab our vocab&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AutoConfig&lt;/code&gt; will define the model architecture and settings, note that we use the pretrained config here for ease of use, but one can easily modify this config if needed&lt;/li&gt;
&lt;li&gt;&lt;code&gt;model_name&lt;/code&gt; is the model architecture (and optionally model weights) you'd like to use.&lt;ul&gt;
&lt;li&gt;Language Models tested so far with this notebook: &lt;code&gt;roberta-base&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;You can find all of HuggingFace's models at &lt;a href=&quot;https://huggingface.co/models&quot;&gt;https://huggingface.co/models&lt;/a&gt;, most, but not all of them are supported by &lt;code&gt;AutoModel&lt;/code&gt;,&lt;code&gt;AutoConfig&lt;/code&gt; and &lt;code&gt;AutoTokenizer&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can now easily call whichever transformer we like as below:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;roberta-base&amp;#39;&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;lm_model_class&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoModelWithLMHead&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoConfig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;HuggingFace-Tokenizer-&amp;amp;-Vocab&quot;&gt;HuggingFace Tokenizer &amp;amp; Vocab&lt;a class=&quot;anchor-link&quot; href=&quot;#HuggingFace-Tokenizer-&amp;amp;-Vocab&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;We use &lt;code&gt;AutoTokenizer&lt;/code&gt; to generate our pretrained tokenizer. HuggingFace's &lt;code&gt;get_vocab&lt;/code&gt; returns a &lt;code&gt;token : index&lt;/code&gt; dict however Fastai expects &lt;code&gt;vocab&lt;/code&gt; to be a list. Therefore we need to convert this dict to a list to be able to use it in fastai&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoTokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tokenizer_vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;tokenizer_vocab_ls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer_vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])]&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Tokenizer &amp;quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;vm&quot;&gt;__class__&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;quot; vocab length is : &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer_vocab_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;Tokenizer &amp;#34;&amp;lt;class &amp;#39;transformers.tokenization_roberta.RobertaTokenizer&amp;#39;&amp;gt;&amp;#34; vocab length is : 50265
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Special-Tokens&quot;&gt;Special Tokens&lt;a class=&quot;anchor-link&quot; href=&quot;#Special-Tokens&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;Its always good to know what special tokens your tokenizer takes, lets have a look:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;special_tokens_map&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;{&amp;#39;bos_token&amp;#39;: &amp;#39;&amp;lt;s&amp;gt;&amp;#39;,
 &amp;#39;eos_token&amp;#39;: &amp;#39;&amp;lt;/s&amp;gt;&amp;#39;,
 &amp;#39;unk_token&amp;#39;: &amp;#39;&amp;lt;unk&amp;gt;&amp;#39;,
 &amp;#39;sep_token&amp;#39;: &amp;#39;&amp;lt;/s&amp;gt;&amp;#39;,
 &amp;#39;pad_token&amp;#39;: &amp;#39;&amp;lt;pad&amp;gt;&amp;#39;,
 &amp;#39;cls_token&amp;#39;: &amp;#39;&amp;lt;s&amp;gt;&amp;#39;,
 &amp;#39;mask_token&amp;#39;: &amp;#39;&amp;lt;mask&amp;gt;&amp;#39;}&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;FastHugs-Tokenizer&quot;&gt;FastHugs Tokenizer&lt;a class=&quot;anchor-link&quot; href=&quot;#FastHugs-Tokenizer&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;This tokenizer wrapper is initialised with the pretrained HF tokenizer, you can also specify the max_seq_len if you want longer/shorter sequences. Given text it returns tokens and adds separator tokens depending on the model type being used.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# collapse&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FastHugsTokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot; &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        transformer_tokenizer : takes the tokenizer that has been loaded from the tokenizer class&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        model_name : model type set by the user&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        max_seq_len : override default sequence length, typically 512 for bert-like models.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                           `transformer_tokenizer.max_len_single_sentence` and `transformer_tokenizer.max_len_sentences_pair` &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                           both account for the need to add additional special tokens, i.e. for RoBERTa-base &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                           max_len_single_sentence==510, leaving space for the 2 additional special tokens &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                           to be added for the model&amp;#39;s default 512 positional embeddings&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        pair : whether a single sentence (sequence) or pair of sentences are used&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;        Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;            - Tokenized text, up to the max sequence length set by the user or the tokenzier default&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformer_tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;roberta&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                 &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformer_tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len_sentences_pair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;WARNING: max_seq_len needs to be less than or equal to transformer_tokenizer.max_len_sentences_pair&amp;#39;&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len_single_sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;WARNING: max_seq_len needs to be less than or equal to transformer_tokenizer.max_len_single_sentence&amp;#39;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ifnone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len_sentences_pair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
                &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ifnone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len_single_sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;do_tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;Returns tokenized text, adds prefix space if needed, limits the maximum sequence length&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;roberta&amp;#39;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;add_prefix_space&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[:&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[:&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;de_tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;Return string from tokens&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;convert_tokens_to_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__call__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;do_tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;The-Fastai-bit&quot;&gt;The Fastai bit&lt;a class=&quot;anchor-link&quot; href=&quot;#The-Fastai-bit&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h3 id=&quot;fasthugstok-and-our-tok_fn&quot;&gt;&lt;code&gt;fasthugstok&lt;/code&gt; and our &lt;code&gt;tok_fn&lt;/code&gt;&lt;a class=&quot;anchor-link&quot; href=&quot;#fasthugstok-and-our-tok_fn&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Lets incorporate the &lt;code&gt;tokenizer&lt;/code&gt; from HuggingFace into fastai-v2's framework by specifying a function called &lt;code&gt;fasthugstok&lt;/code&gt; that we can then pass on to &lt;code&gt;Tokenizer.from_df&lt;/code&gt;. (Note &lt;code&gt;.from_df&lt;/code&gt; is the only method I have tested)&lt;/p&gt;
&lt;h4 id=&quot;Max-Seqence-Length&quot;&gt;Max Seqence Length&lt;a class=&quot;anchor-link&quot; href=&quot;#Max-Seqence-Length&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;code&gt;max_seq_len&lt;/code&gt; is the longest sequece our tokenizer will output. We can also the max sequence length for the tokenizer by changing &lt;code&gt;max_seq_len&lt;/code&gt;. It uses the tokenizer's default, typically &lt;code&gt;512&lt;/code&gt;. &lt;code&gt;1024&lt;/code&gt; or even &lt;code&gt;2048&lt;/code&gt; can also be used depending on your GPU memory. Note when using pretrained models you won't be able to use a &lt;code&gt;max_seq_len&lt;/code&gt; larger than the default.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;  
&lt;span class=&quot;n&quot;&gt;sentence_pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;fasthugstok&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FastHugsTokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformer_tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                      &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence_pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence_pair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We create a &lt;code&gt;MLMTokenizer&lt;/code&gt; class which inherits from fastai's &lt;code&gt;Tokenizer&lt;/code&gt; in order to fully decode&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MLMTokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rules&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lengths&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rules&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lengths&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_detokenize1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;de_tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;decodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TitledStr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_detokenize1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Set up fastai's &lt;code&gt;Tokenizer.from_df&lt;/code&gt;, we pass &lt;code&gt;rules=[fix_html]&lt;/code&gt; to clean up some of HTML messiness in our text. If you do not want any rules then you sould pass &lt;code&gt;rules=[]&lt;/code&gt; to override fastai's default text processing rules&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fastai_tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MLMTokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text_cols&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res_col_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tok_func&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fasthugstok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                     &lt;span class=&quot;n&quot;&gt;rules&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fix_html&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;post_rules&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fastai_tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rules&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;[&amp;lt;function fastai2.text.core.fix_html(x)&amp;gt;]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Add-Special-Tokens&quot;&gt;Add Special Tokens&lt;a class=&quot;anchor-link&quot; href=&quot;#Add-Special-Tokens&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;BERT-like transformers require special tokens to be added to the sequence, depending on the task, so we need a transform for those too&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AddSpecialTokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;Add special token_ids to the numericalized tokens for Sequence Classification&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TensorText&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build_inputs_with_special_tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Create-MLM-Dataset&quot;&gt;Create MLM Dataset&lt;a class=&quot;anchor-link&quot; href=&quot;#Create-MLM-Dataset&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MLMTokensLabels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        MLM task&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        - Select subset of input token ids, given by `mlm_probability`&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        - Mask a subset of these, `mask_token_prob`&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        - Replace half of the first subset with random tokens&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        - This code most comes from the `mask_tokens` function here https://github.com/huggingface/transformers/blob/a21d4fa410dc3b4c62f93aa0e6bbe4b75a101ee9/examples/run_language_modeling.py#L66&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        Returns: input ids and labels&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mlm_probability&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask_token_prob&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mlm_probability&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_token_prob&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mlm_probability&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask_token_prob&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_gen_probability_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# We sample a few tokens in each sequence for masked-LM training (with probability mlm_probability, defaults to 0.15 in Bert/RoBERTa)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;probability_matrix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;full&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mlm_probability&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;special_tokens_mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_special_tokens_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;already_has_special_tokens&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;probability_matrix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_fill_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;special_tokens_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_pad_token&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;padding_mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_token_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;probability_matrix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_fill_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;padding_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probability_matrix&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_replace_with_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# for `mask_token_prob`% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;indices_replaced&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bernoulli&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;full&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_token_prob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_indices&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices_replaced&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;convert_tokens_to_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices_replaced&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_replace_with_other&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices_replaced&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# 1-`mask_token_prob`)/210% of the time, we replace masked input tokens with random word&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;indices_random&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bernoulli&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;full&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices_replaced&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;random_words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;long&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices_random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices_random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_token&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;ne&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;This tokenizer does not have a mask token which is necessary for masked language modeling.&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Get probability of whether a token will be masked&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;probability_matrix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_gen_probability_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Create random mask indices according to probability matrix&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;masked_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bernoulli&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;probability_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Mask the labels for indices that are NOT masked, we only compute loss on masked tokens&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;  
        
        &lt;span class=&quot;c1&quot;&gt;# Randomly replace with mask token&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices_replaced&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_replace_with_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Randomly replace with mask token&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_replace_with_other&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices_replaced&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# The rest of the time (10% of the time) we keep the masked input tokens unchanged&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# collapse&lt;/span&gt;
&lt;span class=&quot;nd&quot;&gt;@Numericalize&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;decodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&amp;#39;Add the ability to parse masks for the loss function, set as `-100`&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tmp_vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tmp_vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&amp;lt;loss_mask&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp_vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp_vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PAD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# collapse&lt;/span&gt;
&lt;span class=&quot;nd&quot;&gt;@delegates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;Doesn&amp;#39;t create a tuple in __getitem__ as x is already a tuple&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dl_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dl_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dl_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__getitem__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# same as Datasets.__getitem__ but not wrapped in a tuple&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tl&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_indexer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Our dataset is now ready to be created, lets look at an some of our (x,y) that will be passed to the model. When &lt;code&gt;-100&lt;/code&gt; is passed to our loss function (&lt;code&gt;nn.CrossEntropyLoss&lt;/code&gt;) it will be ignored in the calculation. Our model will also ignore any padding tokens (usually defined as &lt;code&gt;1&lt;/code&gt;) when passed to it.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse-hide&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;splits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ColSplitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attrgetter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;text&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fastai_tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Numericalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer_vocab_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;AddSpecialTokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MLMTokensLabels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dsets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;splits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;splits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dl_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SortedDL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dsets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dsets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;(tensor([    0,  1890,    12,  5225, 24320,    12,  8494, 18421, 50264,   328,
         14938,  1774,   630,    75,   190,   356,    69, 50264, 32819,   784]),
 tensor([ -100,  -100,  -100,  5225,  -100,  -100,  -100, 18421,  -100,  -100,
          -100,  -100,  -100,    75,  -100,  -100,  -100,  4505,  -100,   784]))&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Dataloader&quot;&gt;Dataloader&lt;a class=&quot;anchor-link&quot; href=&quot;#Dataloader&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h3 id=&quot;Padding&quot;&gt;Padding&lt;a class=&quot;anchor-link&quot; href=&quot;#Padding&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;We need to make sure our padding is done correctly as some transformer models prefer padding on the left while others prefer it on the right. &lt;code&gt;tokenizer.padding_side&lt;/code&gt; will tell us which side is correct. e.g., BERT, Roberta prefers padding to the right, so we set &lt;code&gt;pad_first=False&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pad_mlm_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_idx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backwards&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;Function that collect `samples` and adds padding, modified `max_len_l` in fastai&amp;#39;s `pad_input`&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pad_fields&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;#max_len_l = ifnone(max_seq_len, pad_fields.map(lambda f: max([len(s[f]) for s in samples])))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;max_len_l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backwards&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;## Added this line too, removes tuple if present&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_idx&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#TODO: remove items if L.index is fixed&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sl&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;slice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxsize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;slice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;pad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_idx&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backwards&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;retain_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idxx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idxx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;transformer_mlm_padding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence_pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
    &lt;span class=&quot;s1&quot;&gt;&amp;#39;Uses `pad_fields=[0,1]` to pad both input and label&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;padding_side&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;right&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ifnone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_mlm_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                   &lt;span class=&quot;n&quot;&gt;pad_idx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_token_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transformer_mlm_padding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dsets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataloaders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;before_batch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Check-our-batch&quot;&gt;Check our batch&lt;a class=&quot;anchor-link&quot; href=&quot;#Check-our-batch&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;We can see our special RoBERTa tokens (&lt;code&gt;'&amp;lt;s&amp;gt;'&lt;/code&gt;, &lt;code&gt;'&amp;lt;/s&amp;gt;'&lt;/code&gt;), which translate to &lt;code&gt;0, 2&lt;/code&gt; in its vocab, have been added to the start and end of each sequence in the batch. Your can look at these indices in &lt;code&gt;tokenizer.get_vocab()&lt;/code&gt; to confirm this. We can also see that most of the tokens in our target (&lt;code&gt;text_&lt;/code&gt;) are masked out as we only want to calculate the loss on the ~15% of the &lt;code&gt;text&lt;/code&gt; tokens that have been masked.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;one_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;(torch.Size([4, 512]), torch.Size([4, 512]))&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;text&lt;/th&gt;
      &lt;th&gt;text_&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I&amp;lt;mask&amp;gt; fortunate enough to meet&amp;lt;mask&amp;gt; Pal segregatedand still have my DS:TMlishing&amp;lt;mask&amp;gt; autographed by&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt; at a convention shortly&amp;lt;mask&amp;gt; the release, and asked him why he chose to do the film &quot;camp&quot;. Before&amp;lt;mask&amp;gt; could answer, two studio flacks intercepted and lectured me on how the studio &quot;knew best&quot; and how &quot;no one will take such&amp;lt;mask&amp;gt; film seriously&quot;. I had been reading the Bantam reprints for&amp;lt;mask&amp;gt; couple of years thanks&amp;lt;mask&amp;gt; a&amp;lt;mask&amp;gt; (ComiCon attendees of the 1970s will recall 357hawk and his band? I was in&amp;lt;mask&amp;gt; couple&amp;lt;mask&amp;gt; years of that withnd), and had higher hopes than what we&amp;lt;mask&amp;gt;.&amp;lt;mask&amp;gt;\nThe flacks insisted that no high adventure would ever be&amp;lt;mask&amp;gt; seriously, and so doing 'camp&amp;lt;mask&amp;gt; was the&amp;lt;mask&amp;gt; way. Several other fans jumped in gap my&amp;lt;mask&amp;gt;, with Pal listening as best he could. At the end of the little event, Pal&amp;lt;mask&amp;gt; up to&amp;lt;mask&amp;gt; and apologized,&amp;lt;mask&amp;gt; he could have done more and better.\n\nSTAR WARS put the lie to&lt;/td&gt;
      &lt;td&gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; was&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; George&amp;lt;loss_mask&amp;gt; (&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;OB poster&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; him)&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; after&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; he&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; &quot;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; a&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; a&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; to&amp;lt;loss_mask&amp;gt; friend&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Black&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; a&amp;lt;loss_mask&amp;gt; of&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; him&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; hopes&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; got&amp;lt;loss_mask&amp;gt;\n&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; done&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;'&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; only&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; on&amp;lt;loss_mask&amp;gt; side&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; came&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; us&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; wishing&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;,&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;'s&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; that&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; it&amp;lt;loss_mask&amp;gt;'t&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;,&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; rating as&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt;\n&amp;lt;loss_mask&amp;gt; destroying the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; still&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; have&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; to&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; we&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;hero&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;, there&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; second&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;'s&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; serious&amp;lt;loss_mask&amp;gt; Yes&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; with&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; And&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; a&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;sheet&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; leaping&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; with&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; bronze&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; a&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; tie&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;AV&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Next&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; If&amp;lt;loss_mask&amp;gt; knows&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; George&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; San&amp;lt;loss_mask&amp;gt; for the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;&amp;lt;s&amp;gt;&amp;lt;mask&amp;gt; is another one of those 'humans vs insects/eco-horror' features; a theme that was popular in the late 70's.&amp;lt;mask&amp;gt; you can't really call it horror. There's zero suspense and no&amp;lt;mask&amp;gt; events.&amp;lt;mask&amp;gt; other words: this movie&amp;lt;mask&amp;gt; pretty lame. It's not that it&amp;lt;mask&amp;gt; really bad or&amp;lt;mask&amp;gt;; it's just very boring. A construction site near&amp;lt;mask&amp;gt; hotel uncovers a big nest of&amp;lt;mask&amp;gt;. Later on we learn that, probably due to&amp;lt;mask&amp;gt; sorts&amp;lt;mask&amp;gt; pesticides Lounge in the past, their&amp;lt;mask&amp;gt; became poisonous. Some people get bitten and rushed to&amp;lt;mask&amp;gt; hospital and it takes ages for&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt; Vanity the&amp;lt;mask&amp;gt; to figure out what's going on.&amp;lt;mask&amp;gt; Foxworth figures&amp;lt;mask&amp;gt; out first and then you can&amp;lt;mask&amp;gt; him go berserk with a digging machine for what seems like several hours.&amp;lt;mask&amp;gt; they&amp;lt;mask&amp;gt; in the house, waiting&amp;lt;mask&amp;gt; get rescued. And, man, you should see all the efforts they make for&amp;lt;mask&amp;gt; them.&amp;lt;mask&amp;gt; won't spoil too much, but at&amp;lt;mask&amp;gt; point they even use a big&amp;lt;mask&amp;gt;. All the&lt;/td&gt;
      &lt;td&gt;&amp;lt;loss_mask&amp;gt; This&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Only&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; gruesome&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; In&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; is&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;'s&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; something&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; a&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; ants&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; different&amp;lt;loss_mask&amp;gt; of&amp;lt;loss_mask&amp;gt; used&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; bite&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the residents of&amp;lt;loss_mask&amp;gt; hospital&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Robert&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; it&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; see&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Then&amp;lt;loss_mask&amp;gt; flee&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; to&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; all&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; rescuing&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; I&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; one&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; helicopter&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; this&amp;lt;loss_mask&amp;gt; I&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; thinking&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; you&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; on&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; building&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; lots of&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; of&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; are shown&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; movie&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Ant&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; garbage&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; in&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; straw&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; ants&amp;lt;loss_mask&amp;gt; wider shots&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; designers&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; near&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; do&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; in&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; It&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; as&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; IT&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;EN&amp;lt;loss_mask&amp;gt; AT&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; my&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; title&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;K&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; MAN&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; have&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;for&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;'ll&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; in&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Now&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;,&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; The&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt; saw no fewer than 3 filmed productions&amp;lt;mask&amp;gt; H. G. Wells' great novel, &quot;War of&amp;lt;mask&amp;gt; Worlds&quot;. This&amp;lt;mask&amp;gt; perhaps the least well-known and very probably the best of&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt; No other&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt; W&amp;lt;mask&amp;gt;W has ever attempted not only to present the story very much as Wells wrote&amp;lt;mask&amp;gt;, but also Burton create the atmosphere of the time&amp;lt;mask&amp;gt; which it was supposed to take place: the last year of&amp;lt;mask&amp;gt; 19th Century, 1900 Â… using Wells' original setting, in and near Woking&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt;.\n\nIMDb&amp;lt;mask&amp;gt; unfFlyingly to what they regard as &quot;spoilers&quot;. That might apply&amp;lt;mask&amp;gt; some&amp;lt;mask&amp;gt;, where the ending might actually be a&amp;lt;mask&amp;gt;, but with regard to one of the most famous novels in&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt;, it seems positively silly. I have&amp;lt;mask&amp;gt; sympathy&amp;lt;mask&amp;gt; people who have neglected to&amp;lt;mask&amp;gt; one&amp;lt;mask&amp;gt; the seminal works&amp;lt;mask&amp;gt; English literature,&amp;lt;mask&amp;gt; let's get right to the chase. The aliens are destroyed through catching an Earth disease,&amp;lt;mask&amp;gt; hits&amp;lt;mask&amp;gt; have no immunity. If that wo a spoiler, so be&lt;/td&gt;
      &lt;td&gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; year 2005&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; of&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; is&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; them.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; version of&amp;lt;loss_mask&amp;gt;ot&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; it&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; to&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; in&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;, England&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; seems unfriend&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; with&amp;lt;loss_mask&amp;gt; films&amp;lt;loss_mask&amp;gt; where&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; might&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; surprise&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the world&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; have no&amp;lt;loss_mask&amp;gt; for&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; read&amp;lt;loss_mask&amp;gt; of&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; in&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; so&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; against which they&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;'s&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; other&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; 1953 classic&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; to&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;\n&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;' plot&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;, is&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; ï¿½&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; way&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; off due to&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; of&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Century&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; in&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;ides&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; film&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; some&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; an&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; old&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; than&amp;lt;loss_mask&amp;gt;).&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; of&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; are typical of&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;'t&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;,&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; to&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;/white and&amp;lt;loss_mask&amp;gt; on&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; as&amp;lt;loss_mask&amp;gt; described them&amp;lt;loss_mask&amp;gt; have a more&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;feel&quot;.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; destruction&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; more&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; period&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; particularly&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; or brilliant&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; facial&amp;lt;loss_mask&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;&amp;lt;s&amp;gt;&amp;lt;mask&amp;gt; watched Grend&amp;lt;mask&amp;gt; the&amp;lt;mask&amp;gt; night and am compelled&amp;lt;mask&amp;gt; evangelical&amp;lt;mask&amp;gt; a Public Service Announcement.\n\nGrendel is another version of&amp;lt;mask&amp;gt;owulf, the thousand- resulted-&amp;lt;mask&amp;gt; Anglo-Saxon epic poem.&amp;lt;mask&amp;gt; SciFi channeluture a growing catalog of inoffensive&amp;lt;mask&amp;gt; uninterestingxs,&amp;lt;mask&amp;gt; the previews promised an&amp;lt;mask&amp;gt;authentic low-budget mini-epic, but this one refused to&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt; switch channels.&amp;lt;mask&amp;gt; was staggeringly, overwhelmingly, bad&amp;lt;mask&amp;gt; I watched in fascination and horror at the train wreck you&amp;lt;mask&amp;gt;'t tear your eyes away from&amp;lt;mask&amp;gt; I reached for a notepad and managed to capture part of what I was seeing.&amp;lt;mask&amp;gt; following may contain spoilers or might just save your sanity&amp;lt;mask&amp;gt; You've been warned.\n\n- Just to&amp;lt;mask&amp;gt; it over with, Beow&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt; warriors wore horned&amp;lt;mask&amp;gt;.&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt;ial issue compared to what came after. It also appears that the helmets were in a bin and handed&amp;lt;mask&amp;gt; whichever actor wandered by next. Fit,&amp;lt;mask&amp;gt; and function&amp;lt;mask&amp;gt; apparently irrelevant.\n\n- Marina Sirtis&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt; been blackmailed into doing the&amp;lt;mask&amp;gt; by&amp;lt;mask&amp;gt; Ringling Brothers, Barnum and&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt;.&amp;lt;mask&amp;gt; managed to avoid a red rubber nose, but the&lt;/td&gt;
      &lt;td&gt;&amp;lt;loss_mask&amp;gt; I&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;el&amp;lt;loss_mask&amp;gt; other&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; to put together&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Be&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;year&amp;lt;loss_mask&amp;gt;old&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; The&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; has&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; and&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; movies&amp;lt;loss_mask&amp;gt; and&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; in&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; let me&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;. It&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; couldn&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; The&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; contain&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; save&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;\n&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; get&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;ulf's&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; helmets&amp;lt;loss_mask&amp;gt; Triv&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; to&amp;lt;loss_mask&amp;gt; actor&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; appearance&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; were&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; had obviously&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; movie&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Bailey circus&amp;lt;loss_mask&amp;gt; She&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Ben&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; not&amp;lt;loss_mask&amp;gt; be&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; H&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; must have&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; film&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; hadn&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; to&amp;lt;loss_mask&amp;gt; him&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;\n&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; facilitate&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; hairst&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; of&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; sideburn&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; and&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt; prove&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; a&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;-&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; movie&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; this&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;shaped&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;-&amp;lt;loss_mask&amp;gt; and&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; tradition&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; with&amp;lt;loss_mask&amp;gt; volume&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;\n&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; unintended focus&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; movie&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; with&amp;lt;loss_mask&amp;gt; bolts&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; recoil&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Model&quot;&gt;Model&lt;a class=&quot;anchor-link&quot; href=&quot;#Model&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Our model can be instantiated with either pretrained or random weights. We also need to be careful to pass the model the &lt;code&gt;attention_mask&lt;/code&gt; so that the model ignores padding tokens when training.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LMModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lm_model_class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lm_model_class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lm_model_class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;hasattr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;module&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize_token_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;attention_mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_token_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention_mask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attention_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# only return the prediction_scores (and not hidden states and attention)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Pretrained-Language-Model&quot;&gt;Pretrained Language Model&lt;a class=&quot;anchor-link&quot; href=&quot;#Pretrained-Language-Model&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Lets fine-tune our pretrained Language Model. We would typically do this before training the model on our specific text. Note that here we are not training the language model head before we train the full model, but we could do so if we created a splitter and passed it to our learner&lt;/p&gt;
&lt;p&gt;To load the pretrained HuggingFace model just use &lt;code&gt;pretrained=True&lt;/code&gt; when calling your model:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LMModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm_model_class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm_model_class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                  &lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Training&quot;&gt;Training&lt;a class=&quot;anchor-link&quot; href=&quot;#Training&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;From here we train our model as usual using fastai. Note that we use &lt;code&gt;Perplexity&lt;/code&gt; as our metric as it is a good measure of how well a language model is training&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;opt_func&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decouple_wd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CrossEntropyLossFlat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Learner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opt_func&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#splitter=model_splitter, &lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;loss_func&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Perplexity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_fp16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We check our learning rate finder&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse-hide&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;suggestions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stop_div&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;SuggestedLRs(lr_min=0.025118863582611083, lr_steep=0.2089296132326126)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We do some training&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse-hide&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr_max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: left;&quot;&gt;
      &lt;th&gt;epoch&lt;/th&gt;
      &lt;th&gt;train_loss&lt;/th&gt;
      &lt;th&gt;valid_loss&lt;/th&gt;
      &lt;th&gt;accuracy&lt;/th&gt;
      &lt;th&gt;perplexity&lt;/th&gt;
      &lt;th&gt;time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;13.052832&lt;/td&gt;
      &lt;td&gt;11.317341&lt;/td&gt;
      &lt;td&gt;0.052725&lt;/td&gt;
      &lt;td&gt;82235.375000&lt;/td&gt;
      &lt;td&gt;00:32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;8.539399&lt;/td&gt;
      &lt;td&gt;5.935386&lt;/td&gt;
      &lt;td&gt;0.049121&lt;/td&gt;
      &lt;td&gt;378.185822&lt;/td&gt;
      &lt;td&gt;00:32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1.660586&lt;/td&gt;
      &lt;td&gt;0.785814&lt;/td&gt;
      &lt;td&gt;0.493350&lt;/td&gt;
      &lt;td&gt;2.194192&lt;/td&gt;
      &lt;td&gt;00:32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;0.731211&lt;/td&gt;
      &lt;td&gt;0.768679&lt;/td&gt;
      &lt;td&gt;0.493125&lt;/td&gt;
      &lt;td&gt;2.156916&lt;/td&gt;
      &lt;td&gt;00:32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;0.732979&lt;/td&gt;
      &lt;td&gt;0.772890&lt;/td&gt;
      &lt;td&gt;0.492373&lt;/td&gt;
      &lt;td&gt;2.166016&lt;/td&gt;
      &lt;td&gt;00:32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;0.681202&lt;/td&gt;
      &lt;td&gt;0.695503&lt;/td&gt;
      &lt;td&gt;0.493711&lt;/td&gt;
      &lt;td&gt;2.004716&lt;/td&gt;
      &lt;td&gt;00:33&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;0.660206&lt;/td&gt;
      &lt;td&gt;0.681334&lt;/td&gt;
      &lt;td&gt;0.494063&lt;/td&gt;
      &lt;td&gt;1.976512&lt;/td&gt;
      &lt;td&gt;00:33&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;0.469388&lt;/td&gt;
      &lt;td&gt;0.641964&lt;/td&gt;
      &lt;td&gt;0.495615&lt;/td&gt;
      &lt;td&gt;1.900209&lt;/td&gt;
      &lt;td&gt;00:33&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;0.512519&lt;/td&gt;
      &lt;td&gt;0.612524&lt;/td&gt;
      &lt;td&gt;0.494834&lt;/td&gt;
      &lt;td&gt;1.845082&lt;/td&gt;
      &lt;td&gt;00:33&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;0.545736&lt;/td&gt;
      &lt;td&gt;0.625833&lt;/td&gt;
      &lt;td&gt;0.495205&lt;/td&gt;
      &lt;td&gt;1.869804&lt;/td&gt;
      &lt;td&gt;00:33&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;And we see how our loss progressed&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Lets-Look-at-the-model's-predictions&quot;&gt;Lets Look at the model's predictions&lt;a class=&quot;anchor-link&quot; href=&quot;#Lets-Look-at-the-model's-predictions&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Manually checking how well our model makes predictions for masked tokens is a simple way to see how it is training&lt;/p&gt;
&lt;p&gt;Here function &lt;code&gt;get_mask_pred&lt;/code&gt; takes masked string given by the user and returns the &lt;code&gt;topk&lt;/code&gt; predictions given by the model for that masked token. With it we can sanity check that our model has learned something useful!&lt;/p&gt;
&lt;p&gt;*Note that &lt;code&gt;get_mask_pred&lt;/code&gt; is mostly code from &lt;code&gt;FillMaskPipeline&lt;/code&gt; in HuggingFace's Transformers repo, full credit to them!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_mask_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;Code lightly modified from `FillMaskPipeline` in the HuggingFace Transformers library&amp;quot;&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;aa&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fastai_tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Numericalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer_vocab_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AddSpecialTokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;outs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;masked_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_token_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nonzero&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;probs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vv&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vv&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;word&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Input text&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;score&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;token&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;sequence&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)})&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_token_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;word&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;score&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;token&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;sequence&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)})&lt;/span&gt; 

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Here we can input our own masked sentence and see how the model does. Note that even without fine-tuning the performance below will still be very strong as the pretrained RoBERTa model is very strong.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;I was walking to &amp;lt;mask&amp;gt; when I came across a cat on the road&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pred2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_mask_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;word&lt;/th&gt;
      &lt;th&gt;score&lt;/th&gt;
      &lt;th&gt;token&lt;/th&gt;
      &lt;th&gt;sequence&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Input text&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to&amp;lt;mask&amp;gt; when I came across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;school&lt;/td&gt;
      &lt;td&gt;0.791473&lt;/td&gt;
      &lt;td&gt;334&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to school when I came across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;church&lt;/td&gt;
      &lt;td&gt;0.068957&lt;/td&gt;
      &lt;td&gt;2352&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to church when I came across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;work&lt;/td&gt;
      &lt;td&gt;0.068007&lt;/td&gt;
      &lt;td&gt;173&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to work when I came across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;breakfast&lt;/td&gt;
      &lt;td&gt;0.007202&lt;/td&gt;
      &lt;td&gt;7080&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to breakfast when I came across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;strong&gt;Not bad at all!&lt;/strong&gt; Now lets see how it does on a movie review, lets look at an example from our validation set. We mask the word &lt;code&gt;might&lt;/code&gt; from the first sentence of the reivew, &lt;code&gt;... shows what might happen...&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_indices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;txts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;txts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;800&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# our validation split starts at index 800&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;&amp;lt;mask&amp;gt;&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pred1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_mask_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;word&lt;/th&gt;
      &lt;th&gt;score&lt;/th&gt;
      &lt;th&gt;token&lt;/th&gt;
      &lt;th&gt;sequence&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Input text&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what&amp;lt;mask&amp;gt; happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;b...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;would&lt;/td&gt;
      &lt;td&gt;0.809723&lt;/td&gt;
      &lt;td&gt;74&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what would happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;b...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;might&lt;/td&gt;
      &lt;td&gt;0.131539&lt;/td&gt;
      &lt;td&gt;429&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;b...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;could&lt;/td&gt;
      &lt;td&gt;0.042638&lt;/td&gt;
      &lt;td&gt;115&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what could happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;b...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;will&lt;/td&gt;
      &lt;td&gt;0.009556&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what will happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Boom, pretty darn good! Lets try the same example, replacing &lt;code&gt;ancient&lt;/code&gt; in &lt;code&gt;discovery of ancient documents&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_indices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;54&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;txts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;txts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;800&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# our validation split starts at index 800&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;&amp;lt;mask&amp;gt;&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pred1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_mask_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;word&lt;/th&gt;
      &lt;th&gt;score&lt;/th&gt;
      &lt;th&gt;token&lt;/th&gt;
      &lt;th&gt;sequence&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Input text&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of&amp;lt;mask&amp;gt; documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br ...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;historical&lt;/td&gt;
      &lt;td&gt;0.585666&lt;/td&gt;
      &lt;td&gt;4566&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of historical documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;old&lt;/td&gt;
      &lt;td&gt;0.086817&lt;/td&gt;
      &lt;td&gt;793&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of old documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;obscure&lt;/td&gt;
      &lt;td&gt;0.040825&lt;/td&gt;
      &lt;td&gt;23732&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of obscure documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;b...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;ancient&lt;/td&gt;
      &lt;td&gt;0.035504&lt;/td&gt;
      &lt;td&gt;8178&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;b...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Again, pretty solid predictions!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Train-a-Language-Model-from-Scratch!&quot;&gt;Train a Language Model from Scratch!&lt;a class=&quot;anchor-link&quot; href=&quot;#Train-a-Language-Model-from-Scratch!&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;We can follow the same procedure to train a language model from scratch by using &lt;code&gt;pretrained=False&lt;/code&gt; when seeing up our model&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LMModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm_model_class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm_model_class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                  &lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;opt_func&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decouple_wd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CrossEntropyLossFlat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Learner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opt_func&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_func&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Perplexity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_fp16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Training&quot;&gt;Training&lt;a class=&quot;anchor-link&quot; href=&quot;#Training&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Untrained&quot;&gt;Untrained&lt;a class=&quot;anchor-link&quot; href=&quot;#Untrained&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Again, lets look at the predictions:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;I was walking to &amp;lt;mask&amp;gt; when I cam across a cat on the road&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pred2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_mask_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;word&lt;/th&gt;
      &lt;th&gt;score&lt;/th&gt;
      &lt;th&gt;token&lt;/th&gt;
      &lt;th&gt;sequence&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Input text&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to&amp;lt;mask&amp;gt; when I cam across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;the&lt;/td&gt;
      &lt;td&gt;0.037963&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to the when I cam across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt;0.036504&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to. when I cam across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;,&lt;/td&gt;
      &lt;td&gt;0.033266&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to, when I cam across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;of&lt;/td&gt;
      &lt;td&gt;0.024381&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to of when I cam across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Pretty bad ðŸ‘Ž, and see how the unconfident it is in its predictions! This doesn't perform well because we have only used 800 movie reviews to train our model, we'll need a lot more text to get decent results!&lt;/p&gt;
&lt;p&gt;Again, just for fun, lets see how it does on a movie review, lets look at an example from our validation set. We mask the word &lt;code&gt;might&lt;/code&gt; from the first sentence of the reivew, &lt;code&gt;... shows what might happen...&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_indices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;txts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;txts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;800&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# our validation split starts at index 800&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;&amp;lt;mask&amp;gt;&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pred1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_mask_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;word&lt;/th&gt;
      &lt;th&gt;score&lt;/th&gt;
      &lt;th&gt;token&lt;/th&gt;
      &lt;th&gt;sequence&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Input text&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what&amp;lt;mask&amp;gt; happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;b...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;,&lt;/td&gt;
      &lt;td&gt;0.044226&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what, happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;S...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;the&lt;/td&gt;
      &lt;td&gt;0.035027&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what the happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br ...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt;0.028172&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what. happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;S...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;and&lt;/td&gt;
      &lt;td&gt;0.025764&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what and happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br ...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Ewww..&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_indices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;54&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;txts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;txts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;800&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# our validation split starts at index 800&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;&amp;lt;mask&amp;gt;&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pred1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_mask_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;word&lt;/th&gt;
      &lt;th&gt;score&lt;/th&gt;
      &lt;th&gt;token&lt;/th&gt;
      &lt;th&gt;sequence&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Input text&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of&amp;lt;mask&amp;gt; documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br ...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;the&lt;/td&gt;
      &lt;td&gt;0.036510&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of the documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;,&lt;/td&gt;
      &lt;td&gt;0.035627&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of, documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;Sta...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;and&lt;/td&gt;
      &lt;td&gt;0.029176&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of and documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt;0.029063&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of. documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;Sta...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Yuck!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Notes-&amp;amp;-Hacky-Bits&quot;&gt;Notes &amp;amp; Hacky Bits&lt;a class=&quot;anchor-link&quot; href=&quot;#Notes-&amp;amp;-Hacky-Bits&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h4 id=&quot;Notes&quot;&gt;Notes&lt;a class=&quot;anchor-link&quot; href=&quot;#Notes&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The validation set will change slightly due to random masking. While the data in the validaion set remains constant, different tokens will be masked each time the validation dataloader is called due to &lt;code&gt;MLMTokensLabels&lt;/code&gt; calling a random probability each time.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If a perfectly reproducable validation set is needed then you'll probably have to create a separate transform for it's masking and set it's &lt;code&gt;split_idx = 1&lt;/code&gt;.  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I didn't have time to get &lt;code&gt;learn.predict&lt;/code&gt; working. One issue that needs to be fixed is that &lt;code&gt;MLMTokensLabels&lt;/code&gt; transform shouldn't be called on your masked input text as it will add more masks, which you don't want.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;FastHugsTokenizer&lt;/code&gt; will have to be modified to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;enable sequence lengths larger than the tokenizer default&lt;/li&gt;
&lt;li&gt;to use a non-pretrained tokenizer (e.g. one you trained yourself)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The HuggingFace &lt;code&gt;encode_plus&lt;/code&gt; or &lt;code&gt;batch_encode_plus&lt;/code&gt; functions are great and I would have used them, but don't play nice with fastai multiprocessiing&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Hacks&quot;&gt;Hacks&lt;a class=&quot;anchor-link&quot; href=&quot;#Hacks&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;I had to overwrite &lt;code&gt;__getitem__&lt;/code&gt; in the &lt;code&gt;Datasets&lt;/code&gt; class so that it wouldn't return a tuple as what it thinks is our &lt;code&gt;x&lt;/code&gt; is actually our &lt;code&gt;(x,y)&lt;/code&gt;. Wrapping this tuple in anoother tuple causes headaches down the line. Creating a custom &lt;code&gt;Datasets&lt;/code&gt; class and inheriting from it didn't work as &lt;code&gt;learn.predict&lt;/code&gt; calls on &lt;code&gt;Datasets&lt;/code&gt; and not the custom dataset class.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The function &lt;code&gt;get_mask_pred&lt;/code&gt; (used to view predictions of masked text) is mostly code from &lt;code&gt;FillMaskPipeline&lt;/code&gt; in HuggingFace's Transformers repo, full credit to them!&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Give-me-a-shout-&amp;#128227;&quot;&gt;Give me a shout &amp;#128227;&lt;a class=&quot;anchor-link&quot; href=&quot;#Give-me-a-shout-&amp;#128227;&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Thats it for this, I hope you found it useful and learned a thing or two. If you have any questions or would like to get in touch you can find me on Twitter &lt;a href=&quot;www.twitter.com/mcgenergy&quot;&gt;@mcgenergy&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Morgan McGuire</name></author><summary type="html"></summary></entry><entry><title type="html">Fastpages Notebook Blog Post</title><link href="https://www.ntentional.com/jupyter/2020/02/20/test.html" rel="alternate" type="text/html" title="Fastpages Notebook Blog Post" /><published>2020-02-20T00:00:00-06:00</published><updated>2020-02-20T00:00:00-06:00</updated><id>https://www.ntentional.com/jupyter/2020/02/20/test</id><content type="html" xml:base="https://www.ntentional.com/jupyter/2020/02/20/test.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-02-20-test.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;About&quot;&gt;About&lt;a class=&quot;anchor-link&quot; href=&quot;#About&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;This notebook is a demonstration of some of capabilities of &lt;a href=&quot;https://github.com/fastai/fastpages&quot;&gt;fastpages&lt;/a&gt; with notebooks.&lt;/p&gt;
&lt;p&gt;With &lt;code&gt;fastpages&lt;/code&gt; you can save your jupyter notebooks into the &lt;code&gt;_notebooks&lt;/code&gt; folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Front-Matter&quot;&gt;Front Matter&lt;a class=&quot;anchor-link&quot; href=&quot;#Front-Matter&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# &quot;My Title&quot;
&amp;gt; &quot;Awesome summary&quot;

- toc:true- branch: master- badges: true- comments: true
- author: Hamel Husain &amp;amp; Jeremy Howard
- categories: [fastpages, jupyter]&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Setting &lt;code&gt;toc: true&lt;/code&gt; will automatically generate a table of contents&lt;/li&gt;
&lt;li&gt;Setting &lt;code&gt;badges: true&lt;/code&gt; will automatically include GitHub and Google Colab links to your notebook.&lt;/li&gt;
&lt;li&gt;Setting &lt;code&gt;comments: true&lt;/code&gt; will enable commenting on your blog post, powered by &lt;a href=&quot;https://github.com/utterance/utterances&quot;&gt;utterances&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the &lt;a href=&quot;https://github.com/fastai/fastpages#front-matter-related-options&quot;&gt;front matter section&lt;/a&gt; of the README.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Markdown-Shortcuts&quot;&gt;Markdown Shortcuts&lt;a class=&quot;anchor-link&quot; href=&quot;#Markdown-Shortcuts&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;A &lt;code&gt;#hide&lt;/code&gt; comment at the top of any code cell will hide &lt;strong&gt;both the input and output&lt;/strong&gt; of that cell in your blog post.&lt;/p&gt;
&lt;p&gt;A &lt;code&gt;#hide_input&lt;/code&gt; comment at the top of any code cell will &lt;strong&gt;only hide the input&lt;/strong&gt; of that cell.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;The comment #hide_input was used to hide the code that produced this.
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;put a &lt;code&gt;#collapse-hide&lt;/code&gt; flag at the top of any cell if you want to &lt;strong&gt;hide&lt;/strong&gt; that cell by default, but give the reader the option to show it:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse-hide&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;altair&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;alt&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;put a &lt;code&gt;#collapse-show&lt;/code&gt; flag at the top of any cell if you want to &lt;strong&gt;show&lt;/strong&gt; that cell by default, but give the reader the option to hide it:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot; open=&quot;&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse-show&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cars&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://vega.github.io/vega-datasets/data/cars.json&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://vega.github.io/vega-datasets/data/movies.json&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sp500&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://vega.github.io/vega-datasets/data/sp500.csv&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;stocks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://vega.github.io/vega-datasets/data/stocks.csv&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;flights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://vega.github.io/vega-datasets/data/flights-5k.json&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Interactive-Charts-With-Altair&quot;&gt;Interactive Charts With Altair&lt;a class=&quot;anchor-link&quot; href=&quot;#Interactive-Charts-With-Altair&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Charts made with Altair remain interactive.  Example charts taken from &lt;a href=&quot;https://github.com/uwdata/visualization-curriculum&quot;&gt;this repo&lt;/a&gt;, specifically &lt;a href=&quot;https://github.com/uwdata/visualization-curriculum/blob/master/altair_interaction.ipynb&quot;&gt;this notebook&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Example-1:-DropDown&quot;&gt;Example 1: DropDown&lt;a class=&quot;anchor-link&quot; href=&quot;#Example-1:-DropDown&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# single-value selection over [Major_Genre, MPAA_Rating] pairs&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# use specific hard-wired values as the initial selected values&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;selection&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;selection_single&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Select&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Major_Genre&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;MPAA_Rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Major_Genre&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Drama&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;MPAA_Rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;R&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Major_Genre&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;binding_select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;genres&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;MPAA_Rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;binding_radio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mpaa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  
&lt;span class=&quot;c1&quot;&gt;# scatter plot, modify opacity based on selection&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_circle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_selection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;selection&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Rotten_Tomatoes_Rating:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;IMDB_Rating:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tooltip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Title:N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;opacity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;selection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;

&lt;div id=&quot;altair-viz-1a49e83878ce4d678d7b162f3d6b510f&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
  (function(spec, embedOpt){
    const outputDiv = document.getElementById(&quot;altair-viz-1a49e83878ce4d678d7b162f3d6b510f&quot;);
    const paths = {
      &quot;vega&quot;: &quot;https://cdn.jsdelivr.net/npm//vega@5?noext&quot;,
      &quot;vega-lib&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lib?noext&quot;,
      &quot;vega-lite&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext&quot;,
      &quot;vega-embed&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-embed@6?noext&quot;,
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () =&gt; resolve(paths[lib]);
        s.onerror = () =&gt; reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName(&quot;head&quot;)[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `&lt;div class=&quot;error&quot; style=&quot;color:red;&quot;&gt;${err}&lt;/div&gt;`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err =&gt; showError(`Javascript Error: ${err.message}&lt;br&gt;This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === &quot;function&quot; &amp;&amp; define.amd) {
      requirejs.config({paths});
      require([&quot;vega-embed&quot;], displayChart, err =&gt; showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === &quot;function&quot;) {
      displayChart(vegaEmbed);
    } else {
      loadScript(&quot;vega&quot;)
        .then(() =&gt; loadScript(&quot;vega-lite&quot;))
        .then(() =&gt; loadScript(&quot;vega-embed&quot;))
        .catch(showError)
        .then(() =&gt; displayChart(vegaEmbed));
    }
  })({&quot;config&quot;: {&quot;view&quot;: {&quot;continuousWidth&quot;: 400, &quot;continuousHeight&quot;: 300}}, &quot;data&quot;: {&quot;url&quot;: &quot;https://vega.github.io/vega-datasets/data/movies.json&quot;}, &quot;mark&quot;: &quot;circle&quot;, &quot;encoding&quot;: {&quot;opacity&quot;: {&quot;condition&quot;: {&quot;value&quot;: 0.75, &quot;selection&quot;: &quot;Select&quot;}, &quot;value&quot;: 0.05}, &quot;tooltip&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Title&quot;}, &quot;x&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;Rotten_Tomatoes_Rating&quot;}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;IMDB_Rating&quot;}}, &quot;selection&quot;: {&quot;Select&quot;: {&quot;type&quot;: &quot;single&quot;, &quot;fields&quot;: [&quot;Major_Genre&quot;, &quot;MPAA_Rating&quot;], &quot;init&quot;: {&quot;Major_Genre&quot;: &quot;Drama&quot;, &quot;MPAA_Rating&quot;: &quot;R&quot;}, &quot;bind&quot;: {&quot;Major_Genre&quot;: {&quot;input&quot;: &quot;select&quot;, &quot;options&quot;: [&quot;Action&quot;, &quot;Adventure&quot;, &quot;Black Comedy&quot;, &quot;Comedy&quot;, &quot;Concert/Performance&quot;, &quot;Documentary&quot;, &quot;Drama&quot;, &quot;Horror&quot;, &quot;Musical&quot;, &quot;Romantic Comedy&quot;, &quot;Thriller/Suspense&quot;, &quot;Western&quot;]}, &quot;MPAA_Rating&quot;: {&quot;input&quot;: &quot;radio&quot;, &quot;options&quot;: [&quot;G&quot;, &quot;PG&quot;, &quot;PG-13&quot;, &quot;R&quot;, &quot;NC-17&quot;, &quot;Not Rated&quot;]}}}}, &quot;$schema&quot;: &quot;https://vega.github.io/schema/vega-lite/v4.0.2.json&quot;}, {&quot;mode&quot;: &quot;vega-lite&quot;});
&lt;/script&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Example-2:-Tooltips&quot;&gt;Example 2: Tooltips&lt;a class=&quot;anchor-link&quot; href=&quot;#Example-2:-Tooltips&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_circle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_selection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;selection_interval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;scales&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encodings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;x&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Rotten_Tomatoes_Rating:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;IMDB_Rating:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Axis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minExtent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# use min extent to stabilize axis title placement&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tooltip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Title:N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Release_Date:N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;IMDB_Rating:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Rotten_Tomatoes_Rating:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;properties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;600&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;

&lt;div id=&quot;altair-viz-c022b476f4fb482ca6f609bf6ed082d2&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
  (function(spec, embedOpt){
    const outputDiv = document.getElementById(&quot;altair-viz-c022b476f4fb482ca6f609bf6ed082d2&quot;);
    const paths = {
      &quot;vega&quot;: &quot;https://cdn.jsdelivr.net/npm//vega@5?noext&quot;,
      &quot;vega-lib&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lib?noext&quot;,
      &quot;vega-lite&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext&quot;,
      &quot;vega-embed&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-embed@6?noext&quot;,
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () =&gt; resolve(paths[lib]);
        s.onerror = () =&gt; reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName(&quot;head&quot;)[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `&lt;div class=&quot;error&quot; style=&quot;color:red;&quot;&gt;${err}&lt;/div&gt;`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err =&gt; showError(`Javascript Error: ${err.message}&lt;br&gt;This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === &quot;function&quot; &amp;&amp; define.amd) {
      requirejs.config({paths});
      require([&quot;vega-embed&quot;], displayChart, err =&gt; showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === &quot;function&quot;) {
      displayChart(vegaEmbed);
    } else {
      loadScript(&quot;vega&quot;)
        .then(() =&gt; loadScript(&quot;vega-lite&quot;))
        .then(() =&gt; loadScript(&quot;vega-embed&quot;))
        .catch(showError)
        .then(() =&gt; displayChart(vegaEmbed));
    }
  })({&quot;config&quot;: {&quot;view&quot;: {&quot;continuousWidth&quot;: 400, &quot;continuousHeight&quot;: 300}}, &quot;data&quot;: {&quot;url&quot;: &quot;https://vega.github.io/vega-datasets/data/movies.json&quot;}, &quot;mark&quot;: &quot;circle&quot;, &quot;encoding&quot;: {&quot;tooltip&quot;: [{&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Title&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Release_Date&quot;}, {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;IMDB_Rating&quot;}, {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;Rotten_Tomatoes_Rating&quot;}], &quot;x&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;Rotten_Tomatoes_Rating&quot;}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;axis&quot;: {&quot;minExtent&quot;: 30}, &quot;field&quot;: &quot;IMDB_Rating&quot;}}, &quot;height&quot;: 400, &quot;selection&quot;: {&quot;selector001&quot;: {&quot;type&quot;: &quot;interval&quot;, &quot;bind&quot;: &quot;scales&quot;, &quot;encodings&quot;: [&quot;x&quot;]}}, &quot;width&quot;: 600, &quot;$schema&quot;: &quot;https://vega.github.io/schema/vega-lite/v4.0.2.json&quot;}, {&quot;mode&quot;: &quot;vega-lite&quot;});
&lt;/script&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Example-3:-More-Tooltips&quot;&gt;Example 3: More Tooltips&lt;a class=&quot;anchor-link&quot; href=&quot;#Example-3:-More-Tooltips&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# select a point for which to provide details-on-demand&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;selection_single&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;encodings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;x&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# limit selection to x-axis value&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;mouseover&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# select on mouseover events&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nearest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# select data point nearest the cursor&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;none&amp;#39;&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;# empty selection includes no data points&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# define our base line chart of stock prices&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;date:T&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;price:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Scale&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;log&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;symbol:N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# base line chart&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# add a rule mark to serve as a guide line&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_rule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;#aaa&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;date:T&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# add circle marks for selected time points, hide unselected points&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_circle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;opacity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_selection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# add white stroked text to provide a legible background for labels&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;align&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;left&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stroke&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;white&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strokeWidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;price:Q&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# add text labels for stock prices&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;align&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;left&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;price:Q&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stocks&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;properties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;700&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;

&lt;div id=&quot;altair-viz-9283d3681fd24aafa3d1e2f9ad193ecf&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
  (function(spec, embedOpt){
    const outputDiv = document.getElementById(&quot;altair-viz-9283d3681fd24aafa3d1e2f9ad193ecf&quot;);
    const paths = {
      &quot;vega&quot;: &quot;https://cdn.jsdelivr.net/npm//vega@5?noext&quot;,
      &quot;vega-lib&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lib?noext&quot;,
      &quot;vega-lite&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext&quot;,
      &quot;vega-embed&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-embed@6?noext&quot;,
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () =&gt; resolve(paths[lib]);
        s.onerror = () =&gt; reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName(&quot;head&quot;)[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `&lt;div class=&quot;error&quot; style=&quot;color:red;&quot;&gt;${err}&lt;/div&gt;`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err =&gt; showError(`Javascript Error: ${err.message}&lt;br&gt;This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === &quot;function&quot; &amp;&amp; define.amd) {
      requirejs.config({paths});
      require([&quot;vega-embed&quot;], displayChart, err =&gt; showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === &quot;function&quot;) {
      displayChart(vegaEmbed);
    } else {
      loadScript(&quot;vega&quot;)
        .then(() =&gt; loadScript(&quot;vega-lite&quot;))
        .then(() =&gt; loadScript(&quot;vega-embed&quot;))
        .catch(showError)
        .then(() =&gt; displayChart(vegaEmbed));
    }
  })({&quot;config&quot;: {&quot;view&quot;: {&quot;continuousWidth&quot;: 400, &quot;continuousHeight&quot;: 300}}, &quot;layer&quot;: [{&quot;mark&quot;: &quot;line&quot;, &quot;encoding&quot;: {&quot;color&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;symbol&quot;}, &quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;date&quot;}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;price&quot;, &quot;scale&quot;: {&quot;type&quot;: &quot;log&quot;}}}}, {&quot;mark&quot;: {&quot;type&quot;: &quot;rule&quot;, &quot;color&quot;: &quot;#aaa&quot;}, &quot;encoding&quot;: {&quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;date&quot;}}, &quot;transform&quot;: [{&quot;filter&quot;: {&quot;selection&quot;: &quot;selector002&quot;}}]}, {&quot;mark&quot;: &quot;circle&quot;, &quot;encoding&quot;: {&quot;color&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;symbol&quot;}, &quot;opacity&quot;: {&quot;condition&quot;: {&quot;value&quot;: 1, &quot;selection&quot;: &quot;selector002&quot;}, &quot;value&quot;: 0}, &quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;date&quot;}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;price&quot;, &quot;scale&quot;: {&quot;type&quot;: &quot;log&quot;}}}, &quot;selection&quot;: {&quot;selector002&quot;: {&quot;type&quot;: &quot;single&quot;, &quot;encodings&quot;: [&quot;x&quot;], &quot;on&quot;: &quot;mouseover&quot;, &quot;nearest&quot;: true, &quot;empty&quot;: &quot;none&quot;}}}, {&quot;mark&quot;: {&quot;type&quot;: &quot;text&quot;, &quot;align&quot;: &quot;left&quot;, &quot;dx&quot;: 5, &quot;dy&quot;: -5, &quot;stroke&quot;: &quot;white&quot;, &quot;strokeWidth&quot;: 2}, &quot;encoding&quot;: {&quot;color&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;symbol&quot;}, &quot;text&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;price&quot;}, &quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;date&quot;}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;price&quot;, &quot;scale&quot;: {&quot;type&quot;: &quot;log&quot;}}}, &quot;transform&quot;: [{&quot;filter&quot;: {&quot;selection&quot;: &quot;selector002&quot;}}]}, {&quot;mark&quot;: {&quot;type&quot;: &quot;text&quot;, &quot;align&quot;: &quot;left&quot;, &quot;dx&quot;: 5, &quot;dy&quot;: -5}, &quot;encoding&quot;: {&quot;color&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;symbol&quot;}, &quot;text&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;price&quot;}, &quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;date&quot;}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;price&quot;, &quot;scale&quot;: {&quot;type&quot;: &quot;log&quot;}}}, &quot;transform&quot;: [{&quot;filter&quot;: {&quot;selection&quot;: &quot;selector002&quot;}}]}], &quot;data&quot;: {&quot;url&quot;: &quot;https://vega.github.io/vega-datasets/data/stocks.csv&quot;}, &quot;height&quot;: 400, &quot;width&quot;: 700, &quot;$schema&quot;: &quot;https://vega.github.io/schema/vega-lite/v4.0.2.json&quot;}, {&quot;mode&quot;: &quot;vega-lite&quot;});
&lt;/script&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Data-Tables&quot;&gt;Data Tables&lt;a class=&quot;anchor-link&quot; href=&quot;#Data-Tables&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;You can display tables per the usual way in your blog:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://vega.github.io/vega-datasets/data/movies.json&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# display table with pandas&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Title&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Worldwide_Gross&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;s1&quot;&gt;&amp;#39;Production_Budget&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Distributor&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;MPAA_Rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;IMDB_Rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Rotten_Tomatoes_Rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Title&lt;/th&gt;
      &lt;th&gt;Worldwide_Gross&lt;/th&gt;
      &lt;th&gt;Production_Budget&lt;/th&gt;
      &lt;th&gt;Distributor&lt;/th&gt;
      &lt;th&gt;MPAA_Rating&lt;/th&gt;
      &lt;th&gt;IMDB_Rating&lt;/th&gt;
      &lt;th&gt;Rotten_Tomatoes_Rating&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;The Land Girls&lt;/td&gt;
      &lt;td&gt;146083.0&lt;/td&gt;
      &lt;td&gt;8000000.0&lt;/td&gt;
      &lt;td&gt;Gramercy&lt;/td&gt;
      &lt;td&gt;R&lt;/td&gt;
      &lt;td&gt;6.1&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;First Love, Last Rites&lt;/td&gt;
      &lt;td&gt;10876.0&lt;/td&gt;
      &lt;td&gt;300000.0&lt;/td&gt;
      &lt;td&gt;Strand&lt;/td&gt;
      &lt;td&gt;R&lt;/td&gt;
      &lt;td&gt;6.9&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;I Married a Strange Person&lt;/td&gt;
      &lt;td&gt;203134.0&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;Lionsgate&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;6.8&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Let's Talk About Sex&lt;/td&gt;
      &lt;td&gt;373615.0&lt;/td&gt;
      &lt;td&gt;300000.0&lt;/td&gt;
      &lt;td&gt;Fine Line&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;13.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;Slam&lt;/td&gt;
      &lt;td&gt;1087521.0&lt;/td&gt;
      &lt;td&gt;1000000.0&lt;/td&gt;
      &lt;td&gt;Trimark&lt;/td&gt;
      &lt;td&gt;R&lt;/td&gt;
      &lt;td&gt;3.4&lt;/td&gt;
      &lt;td&gt;62.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Images&quot;&gt;Images&lt;a class=&quot;anchor-link&quot; href=&quot;#Images&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h3 id=&quot;Local-Images&quot;&gt;Local Images&lt;a class=&quot;anchor-link&quot; href=&quot;#Local-Images&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;You can reference local images and they will be copied and rendered on your blog automatically.  You can include these with the following markdown syntax:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;![](my_icons/fastai_logo.png)&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/fastai_logo.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Remote-Images&quot;&gt;Remote Images&lt;a class=&quot;anchor-link&quot; href=&quot;#Remote-Images&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Remote images can be included with the following markdown syntax:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;![](https://image.flaticon.com/icons/svg/36/36686.svg)&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;https://image.flaticon.com/icons/svg/36/36686.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Animated-Gifs&quot;&gt;Animated Gifs&lt;a class=&quot;anchor-link&quot; href=&quot;#Animated-Gifs&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Animated Gifs work, too!&lt;/p&gt;
&lt;p&gt;&lt;code&gt;![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif)&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Captions&quot;&gt;Captions&lt;a class=&quot;anchor-link&quot; href=&quot;#Captions&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;You can include captions with markdown images like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://www.fast.ai/images/fastai_paper/show_batch.png&quot; alt=&quot;&quot; title=&quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Other-Elements&quot;&gt;Other Elements&lt;a class=&quot;anchor-link&quot; href=&quot;#Other-Elements&quot;&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;GitHub-Flavored-Emojis&quot;&gt;GitHub Flavored Emojis&lt;a class=&quot;anchor-link&quot; href=&quot;#GitHub-Flavored-Emojis&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Typing &lt;code&gt;I give this post two :+1:!&lt;/code&gt; will render this:&lt;/p&gt;
&lt;p&gt;I give this post two :+1:!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Tweetcards&quot;&gt;Tweetcards&lt;a class=&quot;anchor-link&quot; href=&quot;#Tweetcards&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Typing &lt;code&gt;&amp;gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20&lt;/code&gt; will render this:

&lt;center&gt;
    &lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Altair 4.0 is released! &lt;a href=&quot;https://t.co/PCyrIOTcvv&quot;&gt;https://t.co/PCyrIOTcvv&lt;/a&gt;&lt;br /&gt;Try it with:&lt;br /&gt;&lt;br /&gt;  pip install -U altair&lt;br /&gt;&lt;br /&gt;The full list of changes is at &lt;a href=&quot;https://t.co/roXmzcsT58&quot;&gt;https://t.co/roXmzcsT58&lt;/a&gt; ...read on for some highlights. &lt;a href=&quot;https://t.co/vWJ0ZveKbZ&quot;&gt;pic.twitter.com/vWJ0ZveKbZ&lt;/a&gt;&lt;/p&gt;&amp;mdash; Jake VanderPlas (@jakevdp) &lt;a href=&quot;https://twitter.com/jakevdp/status/1204765621767901185?ref_src=twsrc%5Etfw&quot;&gt;December 11, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Youtube-Videos&quot;&gt;Youtube Videos&lt;a class=&quot;anchor-link&quot; href=&quot;#Youtube-Videos&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Typing &lt;code&gt;&amp;gt; youtube: https://youtu.be/XfoYk_Z5AkI&lt;/code&gt; will render this:

&lt;center&gt;
    &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/XfoYk_Z5AkI&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;
&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Boxes-/-Callouts&quot;&gt;Boxes / Callouts&lt;a class=&quot;anchor-link&quot; href=&quot;#Boxes-/-Callouts&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Typing &lt;code&gt;&amp;gt; Warning: There will be no second warning!&lt;/code&gt; will render this:
&lt;div class=&quot;flash flash-error&quot;&gt;
    &lt;svg class=&quot;octicon octicon-alert&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 000 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 00.01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Warning: &lt;/strong&gt;There will be no second warning!
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Typing &lt;code&gt;&amp;gt; Important: Pay attention! It's important.&lt;/code&gt; will render this:
&lt;div class=&quot;flash flash-warn&quot;&gt;
    &lt;svg class=&quot;octicon octicon-zap&quot; viewBox=&quot;0 0 10 16&quot; version=&quot;1.1&quot; width=&quot;10&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M10 7H6l3-7-9 9h4l-3 7 9-9z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Important: &lt;/strong&gt;Pay attention! It&amp;#8217;s important.
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Typing &lt;code&gt;&amp;gt; Tip: This is my tip.&lt;/code&gt; will render this:
&lt;div class=&quot;flash flash-success&quot;&gt;
    &lt;svg class=&quot;octicon octicon-checklist&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M16 8.5l-6 6-3-3L8.5 10l1.5 1.5L14.5 7 16 8.5zM5.7 12.2l.8.8H2c-.55 0-1-.45-1-1V3c0-.55.45-1 1-1h7c.55 0 1 .45 1 1v6.5l-.8-.8c-.39-.39-1.03-.39-1.42 0L5.7 10.8a.996.996 0 000 1.41v-.01zM4 4h5V3H4v1zm0 2h5V5H4v1zm0 2h3V7H4v1zM3 9H2v1h1V9zm0-2H2v1h1V7zm0-2H2v1h1V5zm0-2H2v1h1V3z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Tip: &lt;/strong&gt;This is my tip.
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Typing &lt;code&gt;&amp;gt; Note: Take note of this.&lt;/code&gt; will render this:
&lt;div class=&quot;flash&quot;&gt;
    &lt;svg class=&quot;octicon octicon-info&quot; viewBox=&quot;0 0 14 16&quot; version=&quot;1.1&quot; width=&quot;14&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Note: &lt;/strong&gt;Take note of this.
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Typing &lt;code&gt;&amp;gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine.&lt;/code&gt; will render in the docs:
&lt;div class=&quot;flash&quot;&gt;
    &lt;svg class=&quot;octicon octicon-info octicon octicon-info&quot; viewBox=&quot;0 0 14 16&quot; version=&quot;1.1&quot; width=&quot;14&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Note: &lt;/strong&gt;A doc link to &lt;a href=&quot;https://www.fast.ai/&quot;&gt;an example website: fast.ai&lt;/a&gt; should also work fine.
&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Footnotes&quot;&gt;Footnotes&lt;a class=&quot;anchor-link&quot; href=&quot;#Footnotes&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;You can have footnotes in notebooks, however the syntax is different compared to markdown documents. &lt;a href=&quot;https://github.com/fastai/fastpages/blob/master/_fastpages_docs/NOTEBOOK_FOOTNOTES.md&quot;&gt;This guide provides more detail about this syntax&lt;/a&gt;, which looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;For example, here is a footnote {% fn 1 %}.
And another {% fn 2 %}
{{ 'This is the footnote.' | fndetail: 1 }}
{{ 'This is the other footnote. You can even have a [link](www.github.com)!' | fndetail: 2 }}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, here is a footnote &lt;sup id=&quot;fnref-1&quot; class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;#fn-1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;And another &lt;sup id=&quot;fnref-2&quot; class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;#fn-2&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;footnotes&quot;&gt;&lt;p id=&quot;fn-1&quot;&gt;1. This is the footnote.&lt;a href=&quot;#fnref-1&quot; class=&quot;footnote footnotes&quot;&gt;â†©&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;
&lt;div class=&quot;footnotes&quot;&gt;&lt;p id=&quot;fn-2&quot;&gt;2. This is the other footnote. You can even have a &lt;a href=&quot;www.github.com&quot;&gt;link&lt;/a&gt;!&lt;a href=&quot;#fnref-2&quot; class=&quot;footnote footnotes&quot;&gt;â†©&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.ntentional.com/images/chart-preview.png" /><media:content medium="image" url="https://www.ntentional.com/images/chart-preview.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">An Example Markdown Post</title><link href="https://www.ntentional.com/markdown/2020/01/14/test-markdown-post.html" rel="alternate" type="text/html" title="An Example Markdown Post" /><published>2020-01-14T00:00:00-06:00</published><updated>2020-01-14T00:00:00-06:00</updated><id>https://www.ntentional.com/markdown/2020/01/14/test-markdown-post</id><content type="html" xml:base="https://www.ntentional.com/markdown/2020/01/14/test-markdown-post.html">&lt;h1 id=&quot;example-markdown-post&quot;&gt;Example Markdown Post&lt;/h1&gt;

&lt;h2 id=&quot;basic-setup&quot;&gt;Basic setup&lt;/h2&gt;

&lt;p&gt;Jekyll requires blog post files to be named according to the following format:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;YEAR-MONTH-DAY-filename.md&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Where &lt;code class=&quot;highlighter-rouge&quot;&gt;YEAR&lt;/code&gt; is a four-digit number, &lt;code class=&quot;highlighter-rouge&quot;&gt;MONTH&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;DAY&lt;/code&gt; are both two-digit numbers, and &lt;code class=&quot;highlighter-rouge&quot;&gt;filename&lt;/code&gt; is whatever file name you choose, to remind yourself what this post is about. &lt;code class=&quot;highlighter-rouge&quot;&gt;.md&lt;/code&gt; is the file extension for markdown files.&lt;/p&gt;

&lt;p&gt;The first line of the file should start with a single hash character, then a space, then your title. This is how you create a â€œ&lt;em&gt;level 1 heading&lt;/em&gt;â€ in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line &lt;code class=&quot;highlighter-rouge&quot;&gt;## File names&lt;/code&gt; above.&lt;/p&gt;

&lt;h2 id=&quot;basic-formatting&quot;&gt;Basic formatting&lt;/h2&gt;

&lt;p&gt;You can use &lt;em&gt;italics&lt;/em&gt;, &lt;strong&gt;bold&lt;/strong&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;code font text&lt;/code&gt;, and create &lt;a href=&quot;https://www.markdownguide.org/cheat-sheet/&quot;&gt;links&lt;/a&gt;. Hereâ€™s a footnote &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. Hereâ€™s a horizontal rule:&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;lists&quot;&gt;Lists&lt;/h2&gt;

&lt;p&gt;Hereâ€™s a list:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;item 1&lt;/li&gt;
  &lt;li&gt;item 2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And a numbered list:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;item 1&lt;/li&gt;
  &lt;li&gt;item 2&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;boxes-and-stuff&quot;&gt;Boxes and stuff&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;This is a quotation&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;Toast Toast--warning googoo&quot;&gt;
   &lt;span class=&quot;Toast-icon&quot;&gt;&lt;svg class=&quot;octicon octicon-alert&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 000 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 00.01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/span&gt;
   &lt;span class=&quot;Toast-content&quot;&gt;You can include alert boxes&lt;/span&gt;
&lt;/div&gt;

&lt;p&gt;â€¦andâ€¦&lt;/p&gt;

&lt;div class=&quot;Toast&quot;&gt;
   &lt;span class=&quot;Toast-icon&quot;&gt;&lt;svg class=&quot;octicon octicon-info&quot; viewBox=&quot;0 0 14 16&quot; version=&quot;1.1&quot; width=&quot;14&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/span&gt;
   &lt;span class=&quot;Toast-content&quot;&gt;You can include info boxes&lt;/span&gt;
&lt;/div&gt;

&lt;h2 id=&quot;images&quot;&gt;Images&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/logo.png&quot; alt=&quot;&quot; title=&quot;fast.ai's logo&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;

&lt;p&gt;You can format text and code per usual&lt;/p&gt;

&lt;p&gt;General preformatted text:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Do a thing
do_thing()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Python code and output:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Prints '2'
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Formatting text as shell commands:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;hello world&quot;&lt;/span&gt;
./some_script.sh &lt;span class=&quot;nt&quot;&gt;--option&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;value&quot;&lt;/span&gt;
wget https://example.com/cat_photo1.png
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Formatting text as YAML:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;value&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;another_key&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;another&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;value&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;tables&quot;&gt;Tables&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Column 1&lt;/th&gt;
      &lt;th&gt;Column 2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;A thing&lt;/td&gt;
      &lt;td&gt;Another thing&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;tweetcards&quot;&gt;Tweetcards&lt;/h2&gt;

&lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Altair 4.0 is released! &lt;a href=&quot;https://t.co/PCyrIOTcvv&quot;&gt;https://t.co/PCyrIOTcvv&lt;/a&gt;&lt;br /&gt;Try it with:&lt;br /&gt;&lt;br /&gt;  pip install -U altair&lt;br /&gt;&lt;br /&gt;The full list of changes is at &lt;a href=&quot;https://t.co/roXmzcsT58&quot;&gt;https://t.co/roXmzcsT58&lt;/a&gt; ...read on for some highlights. &lt;a href=&quot;https://t.co/vWJ0ZveKbZ&quot;&gt;pic.twitter.com/vWJ0ZveKbZ&lt;/a&gt;&lt;/p&gt;&amp;mdash; Jake VanderPlas (@jakevdp) &lt;a href=&quot;https://twitter.com/jakevdp/status/1204765621767901185?ref_src=twsrc%5Etfw&quot;&gt;December 11, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;This is the footnote.Â &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">Example Markdown Post</summary></entry></feed>